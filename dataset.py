import os
import random
import math
import numpy as np
import cv2
import torch
import torch.utils.data as data
# from img_utils import Distortion_v2
import utils
import utils_data as ud
from utils1 import *
# train ESRGAN on clean image: use img_LR, img_HR pairs
# train ESRGAN on clean HR image, noisy LR image: produce img_LR_produced generated by downsample generator first
class LRHRDataset(data.Dataset):
    def __init__(self, opt):
        super(LRHRDataset, self).__init__()
        self.opt = opt
        self.imglist_HR = utils.get_files(opt.baseroot_HR)       # read image list from subset list txt

    def __getitem__(self, index):

        # get HR image
        imgpath_HR = self.imglist_HR[index]
        img_HR = ud.read_img(imgpath_HR)                        # BGR image, numpy float32, normalized to [0, 1]
        H, W, C = img_HR.shape

        # get LR image, down-sampling on-the-fly

        # scaled size should be greater than opts.crop_size
        if H < W:
            if H < self.opt.crop_size:
                H_out = self.opt.crop_size
                W_out = int(math.floor(W * float(H_out) / float(H)))
                img_HR = cv2.resize(img_HR, (W_out, H_out))
        else: # W_out < H_out
            if W < self.opt.crop_size:
                W_out = self.opt.crop_size
                H_out = int(math.floor(H * float(W_out) / float(W)))
                img_HR = cv2.resize(img_HR, (W_out, H_out))

        # randomly crop
        rand_h = random.randint(0, max(0, H - self.opt.crop_size))
        rand_w = random.randint(0, max(0, W - self.opt.crop_size))
        img_HR = img_HR[rand_h:rand_h + self.opt.crop_size, rand_w:rand_w + self.opt.crop_size, :]

        # using matlab imresize
        img_LR = ud.imresize_np(img_HR, 1 / self.opt.scale, True)
        if img_LR.ndim == 2:
            img_LR = np.expand_dims(img_LR, axis = 2)

        # BGR to RGB, HWC to CHW, numpy to tensor
        if img_HR.shape[2] == 3:
            img_HR = img_HR[:, :, [2, 1, 0]]
            img_LR = img_LR[:, :, [2, 1, 0]]

        # Distort_random
        add_blur = Distortion_v2(self.opt)
        Size = (img_LR.shape[0], img_LR.shape[1])
        img_LR, _ = add_blur.Distort_random_v3(img_LR, Size)
        # img_LR = cv2.cvtColor(img_LR, cv2.COLOR_BGR2RGB)
        # after_blur_img = cv2.cvtColor(after_blur_img, cv2.COLOR_BGR2RGB)
        # cv2.imwrite('./af.png',after_blur_img)
        # cv2.imwrite('./be.png',img_LR)
        img_LR = img_LR.astype(np.float32)/255.0
        img_HR = torch.from_numpy(img_HR.transpose(2, 0, 1).astype(np.float32)).contiguous()
        img_LR = torch.from_numpy(img_LR.transpose(2, 0, 1).astype(np.float32)).contiguous()

        return img_LR, img_HR

    def __len__(self):
        return len(self.imglist_HR)